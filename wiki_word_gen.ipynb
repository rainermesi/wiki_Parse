{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.5 64-bit ('jupyterlab': conda)",
      "language": "python",
      "name": "python37564bitjupyterlabcondacf7fca067e6349aa91afc37379c5735b"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "wiki_word_gen.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rainermesi/wiki_Parse/blob/master/wiki_word_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhYgRSz-ew-0"
      },
      "source": [
        "## Prep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-phEJn1LheJ"
      },
      "source": [
        "Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpXuoUKUL4hw",
        "outputId": "257c24a6-c35f-4c65-8c89-990a8054ede0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeVLjk-ALheM"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "from collections import defaultdict\n",
        "from collections import Counter"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xT7bOg-Lhed"
      },
      "source": [
        "Read in wikipedia corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNXZHzjfLhee"
      },
      "source": [
        "wiki_full_corpus = open(r'/content/drive/My Drive/DATA/Wikipedia/etwiki_latest/wiki_et.txt','r',encoding='utf-8').read()\n",
        "wiki_word_list = full_corpus.lower().split()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikx68xcQbBMx"
      },
      "source": [
        "Read in Tammsaare corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai1t-pHtbE5Y",
        "outputId": "60c4101d-65fd-431c-e712-2a4efa30803c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install ebooklib\n",
        "import ebooklib\n",
        "from ebooklib import epub"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ebooklib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/38/7d6ab2e569a9165249619d73b7bc6be0e713a899a3bc2513814b6598a84c/EbookLib-0.17.1.tar.gz (111kB)\n",
            "\r\u001b[K     |███                             | 10kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 40kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 61kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 92kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 102kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from ebooklib) (4.2.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from ebooklib) (1.15.0)\n",
            "Building wheels for collected packages: ebooklib\n",
            "  Building wheel for ebooklib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ebooklib: filename=EbookLib-0.17.1-cp36-none-any.whl size=38163 sha256=27755a2c3ef3179c80209ce0062adb5f93487bbc16bc57a871ed22b96bd489d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/11/01/951369cbbf8f96878786a1f4da68bd7ac19a5d945b38e03d54\n",
            "Successfully built ebooklib\n",
            "Installing collected packages: ebooklib\n",
            "Successfully installed ebooklib-0.17.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7agOb2tDbdiJ"
      },
      "source": [
        "book = epub.read_epub(r'/content/drive/My Drive/DATA/Wikipedia/etwiki_latest/Anton_Hansen_Tammsaare_Tode_ja_oigus_I.epub')"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKBECrpNbf9p"
      },
      "source": [
        "book_corpus = []\n",
        "\n",
        "for i in book.get_items_of_type(ebooklib.ITEM_DOCUMENT):\n",
        "  book_corpus.append(i.get_content())"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMAE84Owctxt"
      },
      "source": [
        "# bsoup to parse the html?\n",
        "# https://medium.com/@zazazakaria18/turn-your-ebook-to-text-with-python-in-seconds-2a1e42804913"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOGJJhYjetXu"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXxLbwKmLheo"
      },
      "source": [
        "What are most popular words in corpus?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pKp2g1GLhex"
      },
      "source": [
        "pd_word_series = pd.Series(word_list)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBGEiSHALhe8",
        "outputId": "99814c17-85ae-4f2b-f415-5a1b89e8ca87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pd_word_series.value_counts().head(50)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ja             1148377\n",
              "on              800455\n",
              "kategooria      333385\n",
              "eesti           307631\n",
              "oli             291754\n",
              "ta              271610\n",
              "aastal          249307\n",
              "ka              231168\n",
              "ning            201392\n",
              "et              171516\n",
              "mis             165233\n",
              "kui             156204\n",
              "ei              136771\n",
              "aasta           124229\n",
              "või             112717\n",
              "see             100403\n",
              "oma             100297\n",
              "tema             84331\n",
              "selle            76414\n",
              "viited           74003\n",
              "sai              70914\n",
              "sündinud         66513\n",
              "kuid             65650\n",
              "tartu            64389\n",
              "välislingid      62625\n",
              "the              62323\n",
              "kes              61928\n",
              "pärast           58102\n",
              "seda             57875\n",
              "mille            57853\n",
              "jpg              55724\n",
              "tallinna         55129\n",
              "kus              55090\n",
              "keeles           53840\n",
              "kuni             51982\n",
              "aga              50693\n",
              "of               50308\n",
              "välja            49863\n",
              "aastatel         49489\n",
              "nii              48971\n",
              "olid             45566\n",
              "võib             44797\n",
              "üle              44738\n",
              "ehk              44505\n",
              "nende            44300\n",
              "mida             42336\n",
              "usa              42066\n",
              "saksa            41694\n",
              "aastast          41254\n",
              "näiteks          40722\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmhRYDwoLhfF"
      },
      "source": [
        "How long are words in corpus?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMIU_3JnLhfG"
      },
      "source": [
        "def word_len_df_gen(in_list):\n",
        "    count_list = [len(item) for item in in_list]\n",
        "    count_df = pd.DataFrame.from_dict(Counter(count_list).items())\n",
        "    count_df.sort_values(by=1,ascending=False)\n",
        "    return count_df"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inUlhj8jLhfP",
        "outputId": "e60e29dc-8da5-4b53-f415-ba0a63b374cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        }
      },
      "source": [
        "word_len_df = word_len_df_gen(pd_word_series)\n",
        "word_len_df.head(50)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>4124037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>4261348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>1080924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2905578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>3274568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>5127056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10</td>\n",
              "      <td>2517816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>11</td>\n",
              "      <td>1649642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6</td>\n",
              "      <td>5027484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>13</td>\n",
              "      <td>804707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2</td>\n",
              "      <td>3544262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4</td>\n",
              "      <td>4095951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>15</td>\n",
              "      <td>398361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>582269</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0        1\n",
              "0    8  4124037\n",
              "1    7  4261348\n",
              "2   12  1080924\n",
              "3    3  2905578\n",
              "4    9  3274568\n",
              "5    5  5127056\n",
              "6   10  2517816\n",
              "7   11  1649642\n",
              "8    6  5027484\n",
              "9   13   804707\n",
              "10   2  3544262\n",
              "11   4  4095951\n",
              "12  15   398361\n",
              "13  14   582269"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7h9YO3LS2U4"
      },
      "source": [
        "Create a dictionay for the graph and parse the wiki corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o_jFRgDSQd2"
      },
      "source": [
        "def create_graph_dict(corpus):\n",
        "  graphdict = defaultdict(lambda:defaultdict(int))\n",
        "  for word in corpus:\n",
        "    prev_letter = word[0]\n",
        "    for letter in word[1:]:\n",
        "      graphdict[prev_letter][letter] += 1\n",
        "      prev_letter = letter\n",
        "  return graphdict"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-GWPnV6SStY"
      },
      "source": [
        "graph_dict = create_graph_dict(pd_word_series)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NqL-Cj0U4FP"
      },
      "source": [
        "Clean up the graph dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6otUu3itUuKY"
      },
      "source": [
        "def graph_cleanup(graph):\n",
        "  abc = ['A', 'a', 'B', 'b', 'D', 'd', 'E', 'e', 'F', 'f', 'G', 'g', 'H', 'h', 'I', 'i', 'J', 'j', 'K', 'k', 'L', 'l', 'M', 'm', 'N', 'n', 'O', 'o', 'P', 'p', 'R', 'r', 'S', 's', 'Š', 'š', 'Z', 'z', 'Ž', 'ž', 'T', 't', 'U', 'u', 'V', 'v', 'Õ', 'õ', 'Ä', 'ä', 'Ö', 'ö', 'Ü', 'ü']\n",
        "  abc = list(dict.fromkeys(i.lower() for i in abc))\n",
        "  # clean primary keys\n",
        "  tempgraph = dict((k, graph[k]) for k in abc if k in graph) \n",
        "  # clean nested key value pairs\n",
        "  for letter in abc:\n",
        "    for item in tempgraph[letter].copy():\n",
        "      if item not in abc:\n",
        "        del tempgraph[letter][item]\n",
        "  return tempgraph"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSja7rXsV0Bf"
      },
      "source": [
        "graph_dict = graph_cleanup(graph_dict)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvjoPJmQWL_Y"
      },
      "source": [
        "Traverse the graph_dict and create new words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWYADvqQWRnL"
      },
      "source": [
        "def traverse_graph(graph, word_len=3, start_node=None):\n",
        "  \"\"\"Returns a list of words from a randomly weighted walk.\"\"\"\n",
        "  if word_len <= 0:\n",
        "    return []\n",
        "  \n",
        "  # If not given, pick a start node at random.\n",
        "  if not start_node:\n",
        "    start_node = random.choice(list(graph.keys()))\n",
        "  \n",
        "  \n",
        "  weights = np.array(\n",
        "      list(graph[start_node].values()),\n",
        "      dtype=np.float64)\n",
        "  # Normalize letter counts to sum to 1. Create % weights for each letter.\n",
        "  weights /= weights.sum()\n",
        "\n",
        "  # Pick next letter using weighted distribution.\n",
        "  choices = list(graph[start_node].keys())\n",
        "  chosen_letter = np.random.choice(choices, None, p=weights)\n",
        "  \n",
        "  # recursively build a word until word_len = 0\n",
        "  return [chosen_letter] + traverse_graph(\n",
        "      graph, word_len=word_len-1,\n",
        "      start_node=chosen_letter)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HjrUzqxWkOT",
        "outputId": "4ab9ecd6-eb6d-4b0c-9647-80238733b5b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(10): \n",
        "  print(''.join(traverse_graph(graph_dict,word_len=random.choice(word_len_df[0]))))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ovakulõl\n",
            "omadiinõ\n",
            "eiinoomo\n",
            "slisiks\n",
            "insinis\n",
            "alobestnemä\n",
            "iemuleigluande\n",
            "ridatuvadehere\n",
            "asudmäesahemär\n",
            "tanisks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1maIja60XY0r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}