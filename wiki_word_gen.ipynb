{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.5 64-bit ('jupyterlab': conda)",
      "language": "python",
      "name": "python37564bitjupyterlabcondacf7fca067e6349aa91afc37379c5735b"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "wiki_word_gen.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rainermesi/wiki_Parse/blob/master/wiki_word_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhYgRSz-ew-0"
      },
      "source": [
        "## Prep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-phEJn1LheJ"
      },
      "source": [
        "Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpXuoUKUL4hw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b13f46-0fde-4964-deab-480a2c92a3ba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeVLjk-ALheM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b65dd20-cc7a-4f3d-e049-ebc4f871fc29"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas.core.common import flatten\n",
        "import random\n",
        "import re\n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "import unicodedata\n",
        "! pip install BeautifulSoup4\n",
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: BeautifulSoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xT7bOg-Lhed"
      },
      "source": [
        "Read in wikipedia corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNXZHzjfLhee"
      },
      "source": [
        "wiki_full_corpus = open(r'/content/drive/My Drive/DATA/Wikipedia/etwiki_latest/wiki_et.txt','r',encoding='utf-8').read()\n",
        "wiki_word_list = wiki_full_corpus.lower().split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikx68xcQbBMx"
      },
      "source": [
        "Read in Tammsaare corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai1t-pHtbE5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b28c7c35-8e8e-4cb3-a0f4-d2bab6fa3343"
      },
      "source": [
        "! pip install ebooklib\n",
        "import ebooklib\n",
        "from ebooklib import epub"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ebooklib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/38/7d6ab2e569a9165249619d73b7bc6be0e713a899a3bc2513814b6598a84c/EbookLib-0.17.1.tar.gz (111kB)\n",
            "\r\u001b[K     |███                             | 10kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 20kB 21.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 30kB 18.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 40kB 13.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 51kB 11.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 61kB 12.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 71kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 81kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 92kB 13.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 102kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 12.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from ebooklib) (4.2.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from ebooklib) (1.15.0)\n",
            "Building wheels for collected packages: ebooklib\n",
            "  Building wheel for ebooklib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ebooklib: filename=EbookLib-0.17.1-cp36-none-any.whl size=38163 sha256=1fe5b8eda32611c70cc031c3c76bad4c7d5fe7983336dd1534e11ee25e7396dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/11/01/951369cbbf8f96878786a1f4da68bd7ac19a5d945b38e03d54\n",
            "Successfully built ebooklib\n",
            "Installing collected packages: ebooklib\n",
            "Successfully installed ebooklib-0.17.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7agOb2tDbdiJ"
      },
      "source": [
        "book = epub.read_epub(r'/content/drive/My Drive/DATA/Wikipedia/etwiki_latest/Anton_Hansen_Tammsaare_Tode_ja_oigus_I.epub')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwquWnE_HCQQ",
        "outputId": "66e522b1-4fa9-46f0-f48e-860617b8376e"
      },
      "source": [
        "# \n",
        "# url = 'https://www.luts.ee/e-raamatud/eestikeelsed/epub/Anton_Hansen_Tammsaare_Tahtis_paev.epub'\n",
        "url = 'https://www.luts.ee/e-raamatud/eestikeelsed/epub/Anton_Hansen_Tammsaare_Tode_ja_oigus_I.epub'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('tjo.epub', 'wb').write(r.content)\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "517853"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KxriqoQMC2x"
      },
      "source": [
        "temp = (r.content)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "_KR98mWlJUvB",
        "outputId": "759aff79-1b31-4971-a37f-1d8383970906"
      },
      "source": [
        "epub.read_epub(temp)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-ab4325718751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mepub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_epub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ebooklib/epub.py\u001b[0m in \u001b[0;36mread_epub\u001b[0;34m(name, options)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEpubReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m     \u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m     \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ebooklib/epub.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1397\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ebooklib/epub.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1684\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1686\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZIP_DEFLATED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowZip64\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1687\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBadZipfile\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEpubException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Bad Zip file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0mendrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_EndRecData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m_EndRecData\u001b[0;34m(fpin)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;31m# Determine file size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mfpin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0mfilesize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfpin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'seek'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKBECrpNbf9p"
      },
      "source": [
        "book_corpus = []\n",
        "\n",
        "for i in book.get_items_of_type(ebooklib.ITEM_DOCUMENT):\n",
        "  book_corpus.append(i.get_content())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCFQRcFqhP5c"
      },
      "source": [
        "def epub_to_text(corpus):\n",
        "  blacklist = ['[document]','noscript','header','html','meta','head','input','script']\n",
        "  output_str = ''\n",
        "  output_list = []\n",
        "  for i in corpus:\n",
        "    soup = BeautifulSoup(i,'html.parser')\n",
        "    text = soup.find_all(text=True)\n",
        "    for t in text: \n",
        "      if t.parent.name not in blacklist:\n",
        "        output_list.append(unicodedata.normalize(\"NFKD\",t).strip())\n",
        "  output_list = [i.split() for i in output_list]\n",
        "  output_list = list(flatten(output_list))\n",
        "  output_list_copy = [i for i in output_list if len(i) > 2]\n",
        "  output_list = [i.replace(',','') for i in output_list_copy]\n",
        "  output_list = [i.replace(\"'\",'') for i in output_list]\n",
        "  output_list = [i.replace(\"«\",'') for i in output_list]\n",
        "  output_list = [i.replace(\"»\",'') for i in output_list]\n",
        "  output_list = [i.lower() for i in output_list]\n",
        "  return output_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWHq29MeLOQK"
      },
      "source": [
        "book_word_list = epub_to_text(book_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc2Qh8OYMm0m"
      },
      "source": [
        "book_word_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOGJJhYjetXu"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXxLbwKmLheo"
      },
      "source": [
        "What are most popular words in corpus?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pKp2g1GLhex"
      },
      "source": [
        "pd_word_series = pd.Series(book_word_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBGEiSHALhe8"
      },
      "source": [
        "pd_word_series.value_counts().head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmhRYDwoLhfF"
      },
      "source": [
        "How long are words in corpus?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMIU_3JnLhfG"
      },
      "source": [
        "def word_len_df_gen(in_list):\n",
        "    count_list = [len(item) for item in in_list]\n",
        "    count_df = pd.DataFrame.from_dict(Counter(count_list).items())\n",
        "    count_df.sort_values(by=1,ascending=False)\n",
        "    return count_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inUlhj8jLhfP"
      },
      "source": [
        "word_len_df = word_len_df_gen(pd_word_series)\n",
        "word_len_df.sort_values(by=[1],ascending=False).head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7h9YO3LS2U4"
      },
      "source": [
        "Create a dictionay for the graph and parse the wiki corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o_jFRgDSQd2"
      },
      "source": [
        "def create_graph_dict(corpus):\n",
        "  graphdict = defaultdict(lambda:defaultdict(int))\n",
        "  for word in corpus:\n",
        "    prev_letter = word[0]\n",
        "    for letter in word[1:]:\n",
        "      graphdict[prev_letter][letter] += 1\n",
        "      prev_letter = letter\n",
        "  return graphdict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-GWPnV6SStY"
      },
      "source": [
        "graph_dict = create_graph_dict(pd_word_series)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NqL-Cj0U4FP"
      },
      "source": [
        "Clean up the graph dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6otUu3itUuKY"
      },
      "source": [
        "def graph_cleanup(graph):\n",
        "  abc = ['A', 'a', 'B', 'b', 'D', 'd', 'E', 'e', 'F', 'f', 'G', 'g', 'H', 'h', 'I', 'i', 'J', 'j', 'K', 'k', 'L', 'l', 'M', 'm', 'N', 'n', 'O', 'o', 'P', 'p', 'R', 'r', 'S', 's', 'Š', 'š', 'Z', 'z', 'Ž', 'ž', 'T', 't', 'U', 'u', 'V', 'v', 'Õ', 'õ', 'Ä', 'ä', 'Ö', 'ö', 'Ü', 'ü']\n",
        "  abc = list(dict.fromkeys(i.lower() for i in abc))\n",
        "  # clean primary keys\n",
        "  tempgraph = dict((k, graph[k]) for k in abc if k in graph) \n",
        "  # clean nested key value pairs\n",
        "  for letter in abc:\n",
        "    try:\n",
        "      for item in tempgraph[letter].copy():\n",
        "        if item not in abc:\n",
        "          del tempgraph[letter][item]\n",
        "    except:\n",
        "        print(letter,'not in corpus as key, skipping letter')\n",
        "  return tempgraph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSja7rXsV0Bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "3e6e7168-1d17-4fc8-be86-77887dc7358c"
      },
      "source": [
        "graph_dict = graph_cleanup(graph_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f  not in corpus as key\n",
            "š  not in corpus as key\n",
            "z  not in corpus as key\n",
            "ž  not in corpus as key\n",
            "õ  not in corpus as key\n",
            "ä  not in corpus as key\n",
            "ö  not in corpus as key\n",
            "ü  not in corpus as key\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvjoPJmQWL_Y"
      },
      "source": [
        "Traverse the graph_dict and create new words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWYADvqQWRnL"
      },
      "source": [
        "def traverse_graph(graph, word_len=3, start_node=None):\n",
        "  \"\"\"Returns a list of words from a randomly weighted walk.\"\"\"\n",
        "  if word_len <= 0:\n",
        "    return []\n",
        "  \n",
        "  # If not given, pick a start node at random.\n",
        "  if not start_node:\n",
        "    start_node = random.choice(list(graph.keys()))\n",
        "  \n",
        "  \n",
        "  weights = np.array(\n",
        "      list(graph[start_node].values()),\n",
        "      dtype=np.float64)\n",
        "  # Normalize letter counts to sum to 1. Create % weights for each letter.\n",
        "  weights /= weights.sum()\n",
        "\n",
        "  # Pick next letter using weighted distribution.\n",
        "  choices = list(graph[start_node].keys())\n",
        "  chosen_letter = np.random.choice(choices, None, p=weights)\n",
        "  \n",
        "  # recursively build a word until word_len = 0\n",
        "  return [chosen_letter] + traverse_graph(\n",
        "      graph, word_len=word_len-1,\n",
        "      start_node=chosen_letter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HjrUzqxWkOT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "02b35211-75fd-495a-9d16-898c81b60bbd"
      },
      "source": [
        "for i in range(10): \n",
        "  print(''.join(traverse_graph(graph_dict,word_len=random.choice(word_len_df[0]))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ugakuisuudauistuhtta\n",
            "aava\n",
            "amama\n",
            "telearit\n",
            "sehimitesessetamimohela\n",
            "amakehatsisistugajui\n",
            "udalkubravagiloo\n",
            "sstaragidindale\n",
            "umelmidrulesaredmeev\n",
            "orukiha\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1maIja60XY0r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}